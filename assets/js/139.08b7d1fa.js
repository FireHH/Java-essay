(window.webpackJsonp=window.webpackJsonp||[]).push([[139],{512:function(a,t,s){"use strict";s.r(t);var e=s(7),r=Object(e.a)({},(function(){var a=this,t=a._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[t("h2",{attrs:{id:"前言"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#前言"}},[a._v("#")]),a._v(" 前言")]),a._v(" "),t("p",[a._v("如果你是刚工作或者工作两三年，那HashMap基本上是必问八股文之一。下面是常见的问题，基本已经涵盖面试中最常见的问题。答案比较精简，可能不详细，可针对问题进行自行延伸。")]),a._v(" "),t("h2",{attrs:{id:"_1-hashmap的数据结构"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-hashmap的数据结构"}},[a._v("#")]),a._v(" 1.HashMap的数据结构")]),a._v(" "),t("p",[a._v("jdk1.7采用数组+链表，数组中存key-value结构叫Entry")]),a._v(" "),t("p",[a._v("jdk1.8采用数组+链表+红黑树,数组中存key-value叫Node")]),a._v(" "),t("h2",{attrs:{id:"_2-为什么需要用到链表"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-为什么需要用到链表"}},[a._v("#")]),a._v(" 2.为什么需要用到链表")]),a._v(" "),t("p",[a._v("解决hash冲突，数组长度是有限的，在有限的长度里面我们使用哈希，哈希本身就存在概率性。")]),a._v(" "),t("h2",{attrs:{id:"_3-链表的插入方式"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-链表的插入方式"}},[a._v("#")]),a._v(" 3.链表的插入方式")]),a._v(" "),t("p",[a._v("1.7采用头插法，并发情况下会有死循环的问题，1.8采用尾插法解决。")]),a._v(" "),t("p",[a._v("死循环的原因：扩容转移后，前后链表顺序倒置，在转移过程中修改了原来链表中节点的引用关系。")]),a._v(" "),t("h2",{attrs:{id:"_4-hashmap扩容机制"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_4-hashmap扩容机制"}},[a._v("#")]),a._v(" 4.HashMap扩容机制")]),a._v(" "),t("p",[a._v("数组容量是有限的，数据多次插入，到达一定数量就会进行扩容。")]),a._v(" "),t("ul",[t("li",[a._v("Capacity：HashMap当前长度；")]),a._v(" "),t("li",[a._v("LoadFactor：负载因子，默认值是 0.75f 。")])]),a._v(" "),t("p",[a._v("HashMap的扩容分为两步：")]),a._v(" "),t("ol",[t("li",[a._v("扩容：创建一个新的 Entry 空数组，长度是原数组的2倍；")]),a._v(" "),t("li",[a._v("ReHash：遍历原 Entry 数组，把所有的 Entry 重新 Hash 到新数组。")])]),a._v(" "),t("h2",{attrs:{id:"_5-为什么要rehash"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_5-为什么要rehash"}},[a._v("#")]),a._v(" 5.为什么要rehash？")]),a._v(" "),t("p",[a._v("hash公式：index = HashCode（key）&（Length - 1）\n长度扩大后规则也随之改变。")]),a._v(" "),t("h2",{attrs:{id:"_6-hashmap的默认初始化长度"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_6-hashmap的默认初始化长度"}},[a._v("#")]),a._v(" 6.HashMap的默认初始化长度")]),a._v(" "),t("p",[a._v("初始化大小是16")]),a._v(" "),t("h2",{attrs:{id:"_7-为什么是16"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_7-为什么是16"}},[a._v("#")]),a._v(" 7.为什么是16？")]),a._v(" "),t("p",[a._v("因为在使用不是2的幂的数字时，Length - 1 的值是所有二进制位全为1，这种情况下，index 的结果等同于 HashCode 后几位的值。（15的二进制是 1111）\n只要输入的HashCode本身分布均匀，Hash算法的结果就是均匀的。这是为了实现均匀分布。")]),a._v(" "),t("h2",{attrs:{id:"_8-concurrenthashmap"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_8-concurrenthashmap"}},[a._v("#")]),a._v(" 8.ConcurrentHashMap")]),a._v(" "),t("p",[a._v("ConcurrentHashMap采用了分段锁技术，其中Segment继承于ReetrantLock。不会像HashTable那样不管是put还是get操作都需要做同步处理，理论上ConcurrentHashMap支持Segment数组数量的线程并发。\n每当一个线程占用锁访问一个Segment时，不会影响到其他的Segment。")]),a._v(" "),t("h2",{attrs:{id:"_9-hashmap与concurrenthash"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_9-hashmap与concurrenthash"}},[a._v("#")]),a._v(" 9.HashMap与ConcurrentHash")]),a._v(" "),t("ul",[t("li",[a._v("ConcurrentHash是线程安全的,HashMap是线程不安全的")]),a._v(" "),t("li",[a._v("ConcurrentHash不允许null作为key/value，HashMap允许一个key为null，value不限制")])]),a._v(" "),t("h2",{attrs:{id:"_10-concurrenthash1-7和1-8区别"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_10-concurrenthash1-7和1-8区别"}},[a._v("#")]),a._v(" 10.ConcurrentHash1.7和1.8区别")]),a._v(" "),t("ul",[t("li",[t("p",[a._v("1.7:\nSegment分段锁，Segment继承于ReetrantLock\n核心数据如value，以及链表都是volatile修饰的，保证了获取时的可见性。")])]),a._v(" "),t("li",[t("p",[a._v("1.8:\n抛弃了1.7的分段锁的设计，而采用了CAS + synchronized来保证并发安全性。\nvalue、next都采用了volatile修饰，保证了可见性。\n取消了segment数组，直接用table保存数据，锁的粒度更小，减少并发冲突的概率")])])]),a._v(" "),t("h2",{attrs:{id:"_11-reentrantlock和synchronized的区别"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_11-reentrantlock和synchronized的区别"}},[a._v("#")]),a._v(" 11. ReentrantLock和Synchronized的区别")]),a._v(" "),t("p",[a._v("相同点：")]),a._v(" "),t("ul",[t("li",[a._v("它们都是加锁方式同步；")]),a._v(" "),t("li",[a._v("都是重入锁；")]),a._v(" "),t("li",[a._v("阻塞式的同步")])]),a._v(" "),t("p",[t("img",{attrs:{src:"https://fire-repository.oss-cn-beijing.aliyuncs.com/interview/hashMap.png",alt:""}})])])}),[],!1,null,null,null);t.default=r.exports}}]);