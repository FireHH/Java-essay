(window.webpackJsonp=window.webpackJsonp||[]).push([[174],{546:function(a,r,t){"use strict";t.r(r);var s=t(11),e=Object(s.a)({},(function(){var a=this,r=a._self._c;return r("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[r("h2",{attrs:{id:"rag是什么"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#rag是什么"}},[a._v("#")]),a._v(" RAG是什么？")]),a._v(" "),r("p",[a._v("RAG（Retrieval Augmented Generation）是使用向量数据库进行信息检索的生成式AI。通俗的说，RAG就是将信息检索的结果作为生成式AI的输入，从而实现信息检索和生成式AI的结合。")]),a._v(" "),r("p",[a._v("RAG能够为像大型语言模型（LLMs）这样的生成型 AI 模型提供可靠和最新的外部知识，增强其能力。 LLMs 已经展示了革命性的语言理解和生 成能力，但仍然面临着幻觉和过时的内部知识等局限性。")]),a._v(" "),r("p",[a._v("检索增强型大型语言模型（RA-LLMs） 利用外部知识来解决 LLMs 的局限性，减少仅依赖内部知识的情况。")]),a._v(" "),r("p",[a._v("RAG 的核心是向量数据库，向量数据库是一种用于存储和检索向量的数据库。向量数据库将向量存储为向量空间中的点，并使用向量空间模型（VSM）来检索最相似的向量。")]),a._v(" "),r("h2",{attrs:{id:"rag的价值"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#rag的价值"}},[a._v("#")]),a._v(" RAG的价值")]),a._v(" "),r("ul",[r("li",[a._v("能够解决时效相关的问题，比如查天气，看新闻，让模型知道今夕是何年")]),a._v(" "),r("li",[a._v("能够让模型在一定程度上，按我们想要的方式回答问题：\n"),r("ul",[r("li",[a._v('比如要搭建一个客服机器人，那当用户问起"你们产品怎么样"时，需要通过给模型提供相应品牌资料让它能正确回答--夸夸自家产品再给点购买建议，而不是靠幻觉胡说一通，或者是根据预训练数据中的一个差评来回答；')]),a._v(" "),r("li",[a._v("当用户的问题涉及比较有深度的专业知识时，模型的预训练数据可能不足以支持模型分析，就可以通过搜索文档给出质量更高的结果")])])])]),a._v(" "),r("p",[a._v("其实这两个都可以归结为「通过提供额外信息，提升模型的应答质量」，从闭卷考试变成开卷考试。")]),a._v(" "),r("h2",{attrs:{id:"rag的原理"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#rag的原理"}},[a._v("#")]),a._v(" RAG的原理")]),a._v(" "),r("p",[r("img",{attrs:{src:"https://fire-repository.oss-cn-beijing.aliyuncs.com/2025/1217/rag/rag.png",alt:"rag"}})]),a._v(" "),r("ul",[r("li",[a._v("LLM在回答问题时，会调用向量数据库进行信息检索，并使用检索到的信息进行生成。")]),a._v(" "),r("li",[a._v("RAG方法使得不必为每个特定的任务重新训练整个大模型，只需外挂一个向量数据库，就可以实现信息检索。")]),a._v(" "),r("li",[a._v("RAG模型尤其适合知识密集型任务，如问答、摘要、翻译、代码生成等。")])]),a._v(" "),r("h2",{attrs:{id:"rag的实现"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#rag的实现"}},[a._v("#")]),a._v(" RAG的实现")]),a._v(" "),r("h3",{attrs:{id:"rag的典型范式-naive-rag"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#rag的典型范式-naive-rag"}},[a._v("#")]),a._v(" RAG的典型范式（Naive RAG）")]),a._v(" "),r("p",[a._v("Naive RAG是最简单的RAG，但是也很实用。下图是它的流程：\n"),r("img",{attrs:{src:"https://fire-repository.oss-cn-beijing.aliyuncs.com/2025/1217/rag/rag1.png",alt:"rag"}})]),a._v(" "),r("h3",{attrs:{id:"rag的典型范式-dynamic-advanced-rag"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#rag的典型范式-dynamic-advanced-rag"}},[a._v("#")]),a._v(" RAG的典型范式（Dynamic/Advanced RAG）")]),a._v(" "),r("p",[r("img",{attrs:{src:"https://fire-repository.oss-cn-beijing.aliyuncs.com/2025/1217/rag/rag2.png",alt:"rag"}})]),a._v(" "),r("h3",{attrs:{id:"技术框架与选型"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#技术框架与选型"}},[a._v("#")]),a._v(" 技术框架与选型")]),a._v(" "),r("p",[r("img",{attrs:{src:"https://fire-repository.oss-cn-beijing.aliyuncs.com/2025/1217/rag/rag3.png",alt:"rag"}})]),a._v(" "),r("p",[a._v("LangChain：提供用于构建 LLM RAG 的应用程序框架。")]),a._v(" "),r("ul",[r("li",[a._v("索引流程：使用 pypdf 对文档进行解析并提取信息；随后，采用 RecursiveCharacterTextSplitter 对文档内容进行分块（chunks）；最后，利用 bge-small-zh-v1.5 将分块内容进行向量化处理，并将生成的向量存储在 Faiss 向量库中。")]),a._v(" "),r("li",[a._v("检索流程：使用 bge-small-zh-v1.5 对用户的查询（Query）进行向量化处理；然后，通过 Faiss 向量库对查询向量和文本块向量进行相似度匹配，从而检索出与用户查询最相似的前 top-k 个文本块（chunk）。")]),a._v(" "),r("li",[a._v("生成流程：通过设定提示模板（Prompt），将用户的查询与检索到的参考文本块组合输入到 Qwen 大模型中，生成最终的 RAG 回答。")])]),a._v(" "),r("h3",{attrs:{id:"分块策略"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#分块策略"}},[a._v("#")]),a._v(" 分块策略")]),a._v(" "),r("p",[a._v("分块的目标在于确保每个片段在保留核心语义的同时，具备相对独立的语义完整性，从而使模型在处理时不必依赖广泛的上下文信息，增强检索召回的准确性。分块策略最大的挑战在于"),r("strong",[a._v("确定分块的大小")]),a._v("。")]),a._v(" "),r("p",[a._v("分块的重要性在于它直接影响 RAG 系统的生成质量。")]),a._v(" "),r("ul",[r("li",[a._v("首先，合理的分块能够确保检索到的片段与用户查询信息高度匹配，避免信息冗余或丢失。")]),a._v(" "),r("li",[a._v("其次，分块有助于提升生成内容的连贯性，精心设计的独立语义片段可以降低模型对上下文的依赖，从而增强生成的逻辑性与一致性。")]),a._v(" "),r("li",[a._v("最后，分块策略的选择还会影响系统的响应速度与效率，模型能够更快、更准确地处理和生成内容。")])]),a._v(" "),r("p",[r("img",{attrs:{src:"https://fire-repository.oss-cn-beijing.aliyuncs.com/2025/1217/rag/rag4.png",alt:"rag"}})]),a._v(" "),r("p",[a._v("多种分块策略从本质上来看，由以下三个关键组成部分构成：")]),a._v(" "),r("ul",[r("li",[a._v("大小：每个文档块所允许的最大字符数。")]),a._v(" "),r("li",[a._v("重叠：在相邻数据块之间，重叠字符的数量。")]),a._v(" "),r("li",[a._v("拆分：通过段落边界、分隔符、标记，或语义边界来确定块边界的位置。")])]),a._v(" "),r("p",[a._v("Chunk 切分可视化呈现链接："),r("a",{attrs:{href:"https://chunkviz.up.railway.app/",target:"_blank",rel:"noopener noreferrer"}},[a._v("https://chunkviz.up.railway.app/"),r("OutboundLink")],1)]),a._v(" "),r("p",[r("img",{attrs:{src:"https://fire-repository.oss-cn-beijing.aliyuncs.com/2025/1217/rag/rag5.png",alt:"rag"}})]),a._v(" "),r("p",[r("img",{attrs:{src:"https://fire-repository.oss-cn-beijing.aliyuncs.com/2025/1217/rag/rag6.png",alt:"rag"}})]),a._v(" "),r("h3",{attrs:{id:"embedding-嵌入"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#embedding-嵌入"}},[a._v("#")]),a._v(" Embedding 嵌入")]),a._v(" "),r("p",[r("strong",[a._v("Embedding嵌入")]),a._v("是指将文本、图像、音频、视频等形式的信息映射为高维空间中的密集向量表示。这些向量在语义空间中起到坐标的作用，捕捉对象之间的语义关系和隐含的意义。通过在向量空间中进行计算（例如余弦相似度），可以量化和衡量这些对象之间的语义相似性。")]),a._v(" "),r("p",[r("strong",[a._v("向量检索（Vector Retrieval）")]),a._v(" 是一种基于向量表示的搜索技术，通过计算查询向量与已知文本向量的相似度来识别最相关的文本数据。向量检索的高效性在于，它能在大规模数据集中快速、准确地找到与查询最相关的内容，这得益于向量表示中蕴含的丰富语义信息。")]),a._v(" "),r("p",[r("img",{attrs:{src:"https://fire-repository.oss-cn-beijing.aliyuncs.com/2025/1217/rag/rag7.png",alt:"rag"}})]),a._v(" "),r("h3",{attrs:{id:"embedding-model-嵌入模型"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#embedding-model-嵌入模型"}},[a._v("#")]),a._v(" Embedding Model 嵌入模型")]),a._v(" "),r("p",[r("img",{attrs:{src:"https://fire-repository.oss-cn-beijing.aliyuncs.com/2025/1217/rag/rag8.png",alt:"rag"}})]),a._v(" "),r("p",[a._v("在选择适合的嵌入模型时，需要综合考虑多个因素，包括特定领域的适用性、检索精度、支持的语言、文本块长度、模型大小以及检索效率等因素。\n同时以广泛受到认可的 MTEB（Massive Text Embedding Benchmark）和 C-MTEB（Chinese Massive Text Embedding Benchmark）榜单作为参考。")]),a._v(" "),r("h3",{attrs:{id:"向量数据库工作流"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#向量数据库工作流"}},[a._v("#")]),a._v(" 向量数据库工作流")]),a._v(" "),r("p",[r("img",{attrs:{src:"https://fire-repository.oss-cn-beijing.aliyuncs.com/2025/1217/rag/rag9.png",alt:"rag"}})]),a._v(" "),r("ul",[r("li",[a._v("数据处理与向量化原始数据首先被处理并转化为向量嵌入。这一步通过嵌入模型实现，模型利用深度学习算法提取数据的语义特征，生成适合后续处理的高维向量表示。")]),a._v(" "),r("li",[a._v("向量存储转化后的向量嵌入存储在数据库中。这一环节确保数据在高效检索的同时，能够以优化的方式管理和维护存储资源，以适应不同规模和复杂度的应用需求。")]),a._v(" "),r("li",[a._v("向量索引存储的向量嵌入需要经过索引处理，以便在后续查询中快速定位相关数据。索引过程通过构建特定的结构，使得数据库能够在大规模数据集上实现高效的查询响应。")]),a._v(" "),r("li",[a._v("向量搜索在接收到查询后，数据库通过已建立的索引结构执行相似性搜索，找出与查询向量最为接近的数据点。这一阶段的重点在于平衡搜索的速度与准确性，确保在大数据环境下提供快速且相关的查询结果。常见的向量搜索方法包括余弦相似度、欧几里得距离和曼哈顿距离。其中，余弦相似度主要用于文本处理和信息检索，关注向量之间的角度，以捕捉语义相似性；欧几里得距离则测量向量之间的实际距离，适用于密集特征集的聚类或分类；而曼哈顿距离则通过计算笛卡尔坐标中的绝对差值之和，适用于稀疏数据的处理。")]),a._v(" "),r("li",[a._v("数据检索最后，数据库从匹配的向量中检索出对应的原始数据，并根据特定的需求进行必要的后处理。这一步骤确保最终结果能够准确反映用户的查询意图，并提供有意义的输出。")])]),a._v(" "),r("h3",{attrs:{id:"rag检索-混合检索与重排序技术"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#rag检索-混合检索与重排序技术"}},[a._v("#")]),a._v(" RAG检索：混合检索与重排序技术")]),a._v(" "),r("p",[a._v("在 RAG 检索场景中，首要目标是确保最相关的结果能够出现在候选列表中。向量检索和关键词检索各有其独特优势，混合检索通过结合这多种检索技术，弥补了各自的不足，提供了一种更加全面的搜索方案。")]),a._v(" "),r("p",[a._v("仅具备混合检索的能力还不足以满足需求，检索到的结果还需要经过优化排序。即使检索算法已经能够捕捉到所有相关的结果，重排序过程依然不可或缺。它确保最符合用户意图和查询语义的结果优先展示，从而提升用户的搜索体验和结果的准确性。通过重排序，检索系统不仅能找到相关信息，还能智能地将最重要的信息呈现在用户面前。")]),a._v(" "),r("p",[r("img",{attrs:{src:"https://fire-repository.oss-cn-beijing.aliyuncs.com/2025/1217/rag/rag10.png",alt:"rag"}}),a._v(" "),r("img",{attrs:{src:"https://fire-repository.oss-cn-beijing.aliyuncs.com/2025/1217/rag/rag11.png",alt:"rag"}})]),a._v(" "),r("p",[a._v("2023 年，Microsoft Azure AI《Azure 认知搜索：通过混合检索和排序能力超越向量搜索》")]),a._v(" "),r("h3",{attrs:{id:"混合检索-多路召回"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#混合检索-多路召回"}},[a._v("#")]),a._v(" 混合检索（多路召回）")]),a._v(" "),r("p",[a._v("混合检索，又称融合检索 / 多路召回，是指在检索过程中同时采用多种检索方式，并将各类检索结果进行融合，从而得到最终的检索结果。")]),a._v(" "),r("p",[r("img",{attrs:{src:"https://fire-repository.oss-cn-beijing.aliyuncs.com/2025/1217/rag/rag12.png",alt:"rag"}})]),a._v(" "),r("p",[r("img",{attrs:{src:"https://fire-repository.oss-cn-beijing.aliyuncs.com/2025/1217/rag/rag13.png",alt:"rag"}})]),a._v(" "),r("h3",{attrs:{id:"重排序模型-reranking-model"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#重排序模型-reranking-model"}},[a._v("#")]),a._v(" 重排序模型 Reranking Model")]),a._v(" "),r("p",[a._v("重排序模型（Reranking Model）查询与每个文档块计算对应的相关性分数，并根据这些分数对文档进行重新排序，确保文档按照从最相关到最不相关的顺序排列，并返回前 top-k 个结果。")]),a._v(" "),r("p",[r("img",{attrs:{src:"https://fire-repository.oss-cn-beijing.aliyuncs.com/2025/1217/rag/rag14.png",alt:"rag"}})]),a._v(" "),r("p",[a._v("与嵌入模型不同，重排序模型将用户的查询（Query）和文档块作为输入，直接输出相似度评分，而非生成嵌入向量。目前，市面上可用的重排序模型并不多，商用的有 Cohere，开源的有 BGE、Sentence、Mixedbread、T5-Reranker 等，甚至可以使用指令（Prompt）让大模型（GPT、Claude、通义千问、文心一言等）进行重排，大模型指令参考如下：")]),a._v(" "),r("div",{staticClass:"language- line-numbers-mode"},[r("pre",{pre:!0,attrs:{class:"language-text"}},[r("code",[a._v("[1] {文档块1}\n[2] {文档块2}\n（更多文档块）\n请根据这些文档块与查询的相关性进行排序，以 “1,2,3,4”（文档块数字及逗号隔开的形式），输出排序结果。\n")])]),a._v(" "),r("div",{staticClass:"line-numbers-wrapper"},[r("span",{staticClass:"line-number"},[a._v("1")]),r("br"),r("span",{staticClass:"line-number"},[a._v("2")]),r("br"),r("span",{staticClass:"line-number"},[a._v("3")]),r("br"),r("span",{staticClass:"line-number"},[a._v("4")]),r("br")])]),r("h2",{attrs:{id:"rag效果评估"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#rag效果评估"}},[a._v("#")]),a._v(" RAG效果评估")]),a._v(" "),r("p",[a._v("在 RAG 系统的开发、优化与应用过程中，RAG 效果评估是其中不可或缺的一环。通过建立统一的评估标准，能够公平、客观地比较不同 RAG 系统及其优化方法，从而识别出最佳实践。")]),a._v(" "),r("ol",[r("li",[a._v("评估方式：")])]),a._v(" "),r("ul",[r("li",[a._v("大模型打分：通过使用大语言模型对 RAG 的输出进行自动评分。这类评估方式效率高，能够快速处理大规模的评估任务，但在准确性上可能受到模型本身偏差的影响。")]),a._v(" "),r("li",[a._v("人工打分：由人类评审员对 RAG 的输出进行逐一打分。人工评估方式可以提供更为精确、细致的反馈，特别是在检测生成答案中的细微错误和幻觉时，但其耗时较长，成本较高。")])]),a._v(" "),r("ol",{attrs:{start:"2"}},[r("li",[a._v("评估指标：")])]),a._v(" "),r("ul",[r("li",[a._v("CR 检索相关性（Context Relevancy）：该指标用于测量检索到的信息与查询上下文的相关性。如果检索到的信息偏离了原始查询，后续的生成任务就会受到负面影响。")]),a._v(" "),r("li",[a._v("AR 答案相关性（Answer Relevancy）：衡量生成答案与原始问题之间的相关性。该指标主要评估生成的答案是否能够解决用户的问题，且内容是否逻辑连贯。")]),a._v(" "),r("li",[a._v("F 可信度（Faithfulness）：评估生成的答案中是否存在幻觉（hallucination）或不准确之处。这一指标尤为重要，因为虚假的答案会极大影响用户对 RAG 系统的信任度。")])]),a._v(" "),r("h2",{attrs:{id:"rag发展趋势"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#rag发展趋势"}},[a._v("#")]),a._v(" RAG发展趋势")]),a._v(" "),r("p",[a._v("RAG 本身确实在 2025 年进步不显著，与此同时，RAG 和 Agent 的关系却更加密切，无论是作为 Agent Memory 的支撑，还是搭配 Agent 解锁 DeepResearch。")]),a._v(" "),r("p",[a._v("站在 Agent 的视角，或许可以把 RAG 看作是各种 Tools 中的一个，但是由于 RAG 接管了非结构化数据，接管了 Memory 管理，这使得它是 Agent 各种 Tools 最基础和最重要的之一，我们完全可以说没有 RAG 就没有 Agent 在企业端的真正应用。")]),a._v(" "),r("p",[a._v("RAG 作为单独一层的价值，比过去更加突出。")]),a._v(" "),r("p",[a._v("至于 RAG 在发展中所面临的系列问题，我们还是把它留给时间，毕竟，RAG 本身只是一种架构，它的内涵，需要 Infra 和模型的共同迭代演进。")])])}),[],!1,null,null,null);r.default=e.exports}}]);